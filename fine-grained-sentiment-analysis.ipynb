{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Model Source](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment)\n",
    "\n",
    "\n",
    "# Model training data:\n",
    "|Language |   Number of reviews|\n",
    "|---------|---------|\n",
    "|English |    150k|\n",
    "|Dutch |      80k|\n",
    "|German |     137k|\n",
    "|French |     140k|\n",
    "|Italian |    72k|\n",
    "|Spanish |    50k|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from imblearn.metrics import macro_averaged_mean_absolute_error\n",
    "from torch.nn import Softmax\n",
    "from lxml import html\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def strip_html(s):\n",
    "    return str(html.fromstring(s).text_content())\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\") # uses subword-based tokenization\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "# sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "DetectorFactory.seed = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=pd.read_csv('data/finegrained_sentiment_analysis.csv')\n",
    "data.dropna(inplace=True)\n",
    "print(data.shape)\n",
    "print(data['score'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class imbalance\n",
    "|Class|N|\n",
    "|---|---|\n",
    "|5  |  17574|\n",
    "|4  |   3936|\n",
    "|1  |   2571|\n",
    "|3  |   2078|\n",
    "|2  |   1463|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[~data['review'].duplicated(keep=False)]\n",
    "print(data.shape)\n",
    "print(data)\n",
    "data=data[:5000]\n",
    "\n",
    "data['review_summary'] = data['review_summary'].apply(lambda x: strip_html(x))\n",
    "data['review'] = data['review'].apply(lambda x: strip_html(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(x):\n",
    "    review = x['review']\n",
    "    if (review == '') | (review == np.nan):\n",
    "        return np.nan\n",
    "    try:\n",
    "        lan = detect(review)\n",
    "    except LangDetectException as e:\n",
    "        print(f'Insufficient input text: {x[\"review\"]} - {e}')\n",
    "        lan=np.nan\n",
    "    return lan\n",
    "# data['language'] = data.apply(detect_language, axis=1)\n",
    "# print(data['language'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|language code|N|Language\n",
    "|----|-----|-----|\n",
    "|en   | 25272  |  english   |\n",
    "|de   |     6  |  german    |\n",
    "|es   |     5  |  spanish   |\n",
    "|pt   |     1  |  portuguese    |\n",
    "|fr   |     1  |  french    |\n",
    "|cy   |     1  |  welsh |\n",
    "|tl   |     1  |  tagalog   |\n",
    "|it   |     1  |  italian   |\n",
    "|nl   |     1  |  dutch |\n",
    "|af   |     1  |  afrikaans |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "d=data.copy()\n",
    "\n",
    "def f(x):\n",
    "    review=x['review']\n",
    "    tokens_review = tokenizer(review, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    review_summary=x['review_summary']\n",
    "    tokens_review_summary = tokenizer(review_summary, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    if len(tokens_review.input_ids) > 545:\n",
    "        print(len(tokens_review.input_ids))\n",
    "    with torch.no_grad():\n",
    "        logits_review = model(**tokens_review, return_dict=True).logits\n",
    "        logits_review_summary = model(**tokens_review_summary, return_dict=True).logits\n",
    "    probs_review = logits_review.softmax(-1)[0]\n",
    "    probs_review_summary = logits_review_summary.softmax(-1)[0]\n",
    "    probs_combination = (logits_review * logits_review_summary).softmax(-1)[0]\n",
    "    labels = model.config.id2label\n",
    "    review_class_id = probs_review.argmax().item()\n",
    "    review_summary_class_id = probs_review_summary.argmax().item()\n",
    "    review_combination_class_id = probs_combination.argmax().item()\n",
    "    return pd.Series({\n",
    "        'sentiment_score': int(labels[review_combination_class_id].split(' ')[0]),\n",
    "        'classification_confidence': probs_combination[review_combination_class_id].item(),\n",
    "        'sentiment_score_review': int(labels[review_class_id].split(' ')[0]),\n",
    "        'classification_confidence_review': probs_review[review_class_id].item(),\n",
    "        'sentiment_score_review_summary': int(labels[review_summary_class_id].split(' ')[0]),\n",
    "        'classification_confidence_review_summary': probs_review_summary[review_summary_class_id].item()\n",
    "    }, index=['sentiment_score','classification_confidence', 'sentiment_score_review', 'classification_confidence_review', 'sentiment_score_review_summary', 'classification_confidence_review_summary'])\n",
    "# data = Dataset.from_pandas(d)\n",
    "# data = data.map(lambda e: f(e), batched=True)\n",
    "\n",
    "d[['sentiment_score','classification_confidence', 'sentiment_score_review', 'classification_confidence_review', 'sentiment_score_review_summary', 'classification_confidence_review_summary']] = d.apply(f, axis=1)\n",
    "d['error'] = np.abs(d['score'] - d['sentiment_score'])\n",
    "d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE:\n",
    "`ValueError: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.`\n",
    "\n",
    "\n",
    "--> Zero cases of an imbalanced feature in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d['score'].value_counts(), d['sentiment_score'].value_counts())\n",
    "print(np.sort(d['score'].unique()), np.sort(d['sentiment_score'].unique()))\n",
    "if np.array_equal(np.sort(d['score'].unique()), np.sort(d['sentiment_score'].unique())):\n",
    "    print('Warning, macro averaged will not work.')\n",
    "macro_averaged_mean_absolute_error(d['score'].values , d['sentiment_score'].values, sample_weight=d['votes'])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
